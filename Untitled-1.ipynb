{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchain\n",
    "# !pip install pypdf\n",
    "# !pip install chromadb\n",
    "# !pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.chains import ChatVectorDBChain\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import ConversationalRetrievalChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path = \"./1903.03411.pdf\"\n",
    "loader = PyPDFLoader(pdf_path)\n",
    "pages = loader.load_and_split()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noname manuscript No.\n",
      "(will be inserted by the editor)\n",
      "Heuristics, Answer Set Programming and Markov\n",
      "Decision Process for Solving a Set of Spatial Puzzles\n",
      "Thiago Freitas dos Santos \u0001Paulo\n",
      "E. Santos \u0001Leonardo A. Ferreira \u0001\n",
      "Reinaldo A. C. Bianchi \u0001Pedro Cabalar.\n",
      "Received: date / Accepted: date\n",
      "Abstract Spatial puzzles composed of rigid objects, ﬂexible strings and holes\n",
      "oﬀer interesting domains for reasoning about spatial entities that are common\n",
      "in the human daily-life’s activities. The goal of this work is to investigate the\n",
      "automated solution of this kind of puzzles adapting an algorithm that com-\n",
      "bines Answer Set Programming (ASP) with Markov Decision Process (MDP),\n",
      "algorithm oASP(MDP), to use heuristics accelerating the learning process.\n",
      "ASP is applied to represent the domain as an MDP, while a Reinforcement\n",
      "Learning algorithm (Q-Learning) is used to ﬁnd the optimal policies. In this\n",
      "work, the heuristics were obtained from the solution of relaxed versions of\n",
      "the puzzles. Experiments were performed on deterministic, non-deterministic\n",
      "and non-stationary versions of the puzzles. Results show that the proposed\n",
      "approach can accelerate the learning process, presenting an advantage when\n",
      "compared to the non-heuristic versions of oASP(MDP) and Q-Learning.\n",
      "Keywords Heuristic\u0001Markov Decision Process \u0001Answer Set Programming \u0001\n",
      "Reinforcement Learning \u0001Spatial Puzzles\n",
      "Thiago Freitas dos Santos is sponsored by FAPESP-IBM Proc. 17/07833-9. Paulo E. Santos\n",
      "acknowledges support from FAPESP-IBM Proc. 2016/18792- 9. Leonardo Anjoletto Ferreira\n",
      "acknowledges ﬁnancial support from Coordenação de Aperfeiçoamento de Pessoal de Nível\n",
      "Superior – Brasil (CAPES) – Finance Code 001. Reinaldo Bianchi acknowledges ﬁnancial\n",
      "support from FAPESP Proc. 2016/21047-3.\n",
      "Thiago Freitas dos Santos\n",
      "Centro Universitário FEI; E-mail: thiagosantos38@gmail.com\n",
      "Paulo E. Santos\n",
      "Centro Universitário FEI; E-mail: psantos@fei.edu.br\n",
      "Leonardo A. Ferreira\n",
      "Centro Universitário FEI; E-mail: laferreira@fei.edu.br\n",
      "Reinaldo A. C. Bianchi\n",
      "Centro Universitário FEI; E-mail: rbianchi@fei.edu.br\n",
      "Pedro Cabalar\n",
      "University of Corunna; E-mail: cabalar@udc.esarXiv:1903.03411v1  [cs.AI]  16 Feb 2019\n"
     ]
    }
   ],
   "source": [
    "print(pages[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using embedded DuckDB with persistence: data will be stored in: .\n",
      "No embedding_function provided, using default embedding function: SentenceTransformerEmbeddingFunction\n"
     ]
    }
   ],
   "source": [
    "embbedings = OpenAIEmbeddings()\n",
    "vectordb = Chroma.from_documents(pages, embbedings=embbedings, persist_directory=\".\")\n",
    "vectordb.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dungho/anaconda3/envs/books/lib/python3.10/site-packages/langchain/llms/openai.py:165: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n",
      "/home/dungho/anaconda3/envs/books/lib/python3.10/site-packages/langchain/llms/openai.py:676: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n",
      "/home/dungho/anaconda3/envs/books/lib/python3.10/site-packages/langchain/chains/conversational_retrieval/base.py:191: UserWarning: `ChatVectorDBChain` is deprecated - please use `from langchain.chains import ConversationalRetrievalChain`\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "pdf_qa = ChatVectorDBChain.from_llm(OpenAI(temperature=0.9, model_name='gpt-3.5-turbo'),vectordb)\n",
    "# pdf_qa = ConversationalRetrievalChain.from_llm(OpenAI(temperature=0.9, model_name='gpt-3.5-turbo'), vectordb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: \n",
      "Answer Set Programming (ASP) is a declarative logic programming language that facilitates Non-Monotonic reasoning and it has been successfully used to solve NP-Complete problems. ASP presents advantages such as the possibility to define which solutions are more desirable than others and the capability to work with missing information, among others. ASP relies on a declarative semantics based on the definition of stable models. It is designed to model and solve problems that deal with commonsense reasoning, such as spatial puzzles or spatial non-monotonic reasoning.\n"
     ]
    }
   ],
   "source": [
    "query = \"what is Answer Set Programming?\"\n",
    "\n",
    "result = pdf_qa({\n",
    "    'question': query,\n",
    "    'chat_history': \"\"\n",
    "})\n",
    "\n",
    "print(\"Answer: \")\n",
    "print(result['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'what is Answer Set Programming?',\n",
       " 'chat_history': '',\n",
       " 'answer': 'Answer Set Programming (ASP) is a declarative logic programming language that facilitates Non-Monotonic reasoning and it has been successfully used to solve NP-Complete problems. ASP presents advantages such as the possibility to define which solutions are more desirable than others and the capability to work with missing information, among others. ASP relies on a declarative semantics based on the definition of stable models. It is designed to model and solve problems that deal with commonsense reasoning, such as spatial puzzles or spatial non-monotonic reasoning.'}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: \n",
      "The paper discusses the use of an oASP(MDP) algorithm for solving two versions of the Fisher-man's Folly puzzle - a non-deterministic version and a non-stationary version with moving disks. The authors compare the oASP(MDP) algorithm with a heuristic approach and a traditional oASP(MDP) approach, using metrics such as number of steps and total accumulated return. The results are presented in Figures 6 and 8, along with T test comparisons.\n"
     ]
    }
   ],
   "source": [
    "query = \"Can you summary this paper?\"\n",
    "\n",
    "result = pdf_qa({\n",
    "    'question': query,\n",
    "    'chat_history': \"\"\n",
    "})\n",
    "\n",
    "print(\"Answer: \")\n",
    "print(result['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: \n",
      "The introduction section describes how the goal of the work is to build an autonomous agent capable of dealing with two spatial puzzles: the Fisherman's Folly puzzle and the Rope Ladder puzzle. The authors use an Oracle (a simulation of the puzzle) to allow the agent to interact with the domain. The section also includes a description of the objects used in the puzzles and a figure showing the initial and goal states of the puzzles. Finally, the section introduces Fig. 4, which shows the number of steps and return results for the Original Fisherman's Folly puzzle.\n"
     ]
    }
   ],
   "source": [
    "query = \"Can you summary the introduction section?\"\n",
    "\n",
    "result = pdf_qa({\n",
    "    'question': query,\n",
    "    'chat_history': \"\"\n",
    "})\n",
    "\n",
    "print(\"Answer: \")\n",
    "print(result['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: \n",
      "The motivation of this paper is to build an autonomous agent capable of solving spatial puzzles by using different reinforcement learning algorithms, and to compare their performance based on the number of steps, visited states, and accumulated return values. The paper also explores the use of heuristics to accelerate the learning process.\n"
     ]
    }
   ],
   "source": [
    "query = \"Can you summary the motivation of this paper?\"\n",
    "\n",
    "result = pdf_qa({\n",
    "    'question': query,\n",
    "    'chat_history': \"\"\n",
    "})\n",
    "\n",
    "print(\"Answer: \")\n",
    "print(result['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-Hup9YXWjnBXHUbEkCZ23yDej on requests per min. Limit: 3 / min. Please try again in 20s. Contact support@openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-Hup9YXWjnBXHUbEkCZ23yDej on requests per min. Limit: 3 / min. Please try again in 20s. Contact support@openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-Hup9YXWjnBXHUbEkCZ23yDej on requests per min. Limit: 3 / min. Please try again in 20s. Contact support@openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: \n",
      "The oASP(MDP) algorithm is a reinforcement learning algorithm that receives the set of actions A, an action-value function approximation method M, and a number of episodes n. It initializes the set of observed states S to empty, and then starts a loop that is repeated n times. In each repetition, it observes the current state s and can take two different actions depending on whether the current state is in the set of observed states S or not. If s is not in S, it adds s to S and executes a random action in set A. It then adds the observed transition for this state and action with the choice rule, and updates the description of the action-value function Q(s,a) by finding every answer set for each state added to S in this episode. If s is already in S, it chooses an action as defined by M and executes it. It then updates the value of Q(s,a) as defined by M, and updates the current state s to s0. The algorithm is capable of approximating the action-value function and returning the Q-Table, which defines that the optimal policy is followed if the actions with higher values are executed.\n"
     ]
    }
   ],
   "source": [
    "query = \"please describle the algorithm oASP(MDP)\"\n",
    "\n",
    "result = pdf_qa({\n",
    "    'question': query,\n",
    "    'chat_history': \"\"\n",
    "})\n",
    "\n",
    "print(\"Answer: \")\n",
    "print(result['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "books",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
